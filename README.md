
# Predecir c贸mo se sentir谩 un cliente sobre un producto antes de que lo ordene

[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/zenml)](https://pypi.org/project/zenml/)

**Planteamiento del problema**: A partir de los datos hist贸ricos de un cliente, nuestra tarea es predecir la puntuaci贸n de rese帽a para su pr贸ximo pedido o compra. Usaremos el [conjunto de datos p煤blicos de comercio electr贸nico de Brasil por Olist](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce). Este conjunto de datos contiene informaci贸n de 100,000 pedidos realizados entre 2016 y 2018 en varios marketplaces de Brasil. Sus caracter铆sticas permiten visualizar cargos desde varias dimensiones: estado del pedido, precio, pago, rendimiento del flete, ubicaci贸n del cliente, atributos del producto y, finalmente, rese帽as escritas por clientes. El objetivo aqu铆 es predecir el nivel de satisfacci贸n del cliente para un pedido dado con base en caracter铆sticas como el estado del pedido, precio, pago, etc. Para lograrlo en un entorno real, usaremos [ZenML](https://zenml.io/) para construir una canalizaci贸n lista para producci贸n que prediga la puntuaci贸n de satisfacci贸n del cliente.

Este repositorio tiene como prop贸sito demostrar c贸mo [ZenML](https://github.com/zenml-io/zenml) permite a tu empresa construir y desplegar canalizaciones de aprendizaje autom谩tico de m煤ltiples formas:

- Ofreciendo un marco y plantilla sobre los que puedes basar tu trabajo.
- Integr谩ndose con herramientas como [MLflow](https://mlflow.org/) para despliegue, seguimiento, entre otros.
- Permiti茅ndote construir y desplegar f谩cilmente tus canalizaciones de machine learning.

## :snake: Requisitos de Python

Vamos a los paquetes de Python necesarios. Dentro del entorno de Python de tu preferencia, ejecuta:

```bash
git clone https://github.com/zenml-io/zenml-projects.git
cd zenml-projects/customer-satisfaction
pip install -r requirements.txt
```

Desde ZenML 0.20.0, viene con un panel de control basado en React. Este permite observar tus stacks, componentes y DAGs de las canalizaciones. Para acceder a esto, primero debes [lanzar el servidor y panel de control de ZenML localmente](https://docs.zenml.io/user-guide/starter-guide#explore-the-dashboard), pero antes debes instalar las dependencias opcionales del servidor ZenML:

```bash
pip install zenml["server"]
zenml up
```

Si vas a ejecutar el script `run_deployment.py`, tambi茅n necesitas instalar algunas integraciones con ZenML:

```bash
zenml integration install mlflow -y
```

El proyecto solo puede ejecutarse con un stack de ZenML que tenga un rastreador de experimentos y un implementador de modelos de MLflow como componentes. Para configurarlo:

```bash
zenml integration install mlflow -y
zenml experiment-tracker register mlflow_tracker --flavor=mlflow
zenml model-deployer register mlflow --flavor=mlflow
zenml stack register mlflow_stack -a default -o default -d mlflow -e mlflow_tracker --set
```

##  Recursos y Referencias

Escribimos un blog que explica este proyecto en profundidad: [Predecir c贸mo se sentir谩 un cliente sobre un producto antes de que lo ordene](https://blog.zenml.io/customer_satisfaction/).

Tambi茅n puedes ver el [video](https://youtu.be/L3_pFTlF9EQ) explicativo.

## :thumbsup: La Soluci贸n

Para construir un flujo de trabajo real que prediga la satisfacci贸n del cliente, no basta con entrenar el modelo una vez. Construimos una canalizaci贸n de extremo a extremo para predecir y desplegar continuamente el modelo de ML, junto con una app de datos que utiliza el modelo desplegado.

Esta canalizaci贸n puede escalar en la nube y hacer seguimiento de par谩metros y datos en cada ejecuci贸n. Incluye datos crudos, caracter铆sticas, resultados, el modelo, par谩metros del modelo y predicciones. ZenML facilita construir esta canalizaci贸n de forma simple pero poderosa.

Usamos especialmente la [integraci贸n de MLflow](https://github.com/zenml-io/zenml/tree/main/examples) de ZenML, para:

- Seguir m茅tricas y par谩metros con MLflow tracking.
- Desplegar el modelo con MLflow deployment.
- Mostrar su uso real con [Streamlit](https://streamlit.io/).

### Canalizaci贸n de Entrenamiento

Incluye los siguientes pasos:

- `ingest_data`: Ingesta los datos y crea un `DataFrame`.
- `clean_data`: Limpia los datos y elimina columnas no deseadas.
- `train_model`: Entrena el modelo y lo guarda con [MLflow autologging](https://www.mlflow.org/docs/latest/tracking.html).
- `evaluation`: Eval煤a el modelo y guarda las m茅tricas con MLflow.

### Canalizaci贸n de Despliegue

El archivo `deployment_pipeline.py` extiende la canalizaci贸n de entrenamiento e implementa un flujo de despliegue continuo. Usa un umbral configurable sobre el [MSE](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) como criterio. Adem谩s de los pasos anteriores, incluye:

- `deployment_trigger`: Verifica si el nuevo modelo cumple el criterio para desplegarse.
- `model_deployer`: Despliega el modelo como servicio usando MLflow si se cumple el criterio.

MLflow registra los hiperpar谩metros, m茅tricas y modelo entrenado como artefactos. Se lanza un servidor local de MLflow para servir el modelo, que se actualiza autom谩ticamente si un nuevo modelo supera el umbral.

Una aplicaci贸n Streamlit consume este servicio modelo de forma as铆ncrona, usando:

```python
service = prediction_service_loader(
   pipeline_name="continuous_deployment_pipeline",
   pipeline_step_name="mlflow_model_deployer_step",
   running=False,
)
...
service.predict(...)  # Predecir con datos entrantes
```

Tambi茅n es posible desplegar en entornos m谩s productivos (como Kubernetes) usando otras integraciones de ZenML, como [Seldon](https://github.com/zenml-io/zenml/tree/main/examples/seldon_deployment).

![training_and_deployment_pipeline](_assets/training_and_deployment_pipeline_updated.png)

## :notebook: Ejecutando el c贸digo

Puedes ejecutar ambas canalizaciones as铆:

- Canalizaci贸n de entrenamiento:

```bash
python run_pipeline.py
```

- Canalizaci贸n de despliegue continuo:

```bash
python run_deployment.py
```

##  Demo con Streamlit

Hay una demo en vivo con [Streamlit](https://streamlit.io/) que puedes ver [aqu铆](https://share.streamlit.io/ayush714/customer-satisfaction/main). Puedes ejecutarla localmente con:

```bash
streamlit run streamlit_app.py
```

## :question: Preguntas Frecuentes (FAQ)

1. Al ejecutar la canalizaci贸n de despliegue me aparece: `No Step found for the name mlflow_deployer`.

   **Soluci贸n**: Tu almac茅n de artefactos fue sobrescrito. Debes eliminarlo y volver a ejecutar la canalizaci贸n. Encuentra la ubicaci贸n con:

   ```bash
   zenml artifact-store describe
   ```

   Luego elim铆nalo con:

   锔 **Nota**: 隆Este comando es destructivo! Escribe la ruta cuidadosamente:

   ```bash
   rm -rf RUTA
   ```

2. Me aparece el error: `No Environment component with name mlflow is currently registered.`

   **Soluci贸n**: Olvidaste instalar la integraci贸n MLflow. Inst谩lala con:

   ```bash
   zenml integration install mlflow -y
   ```
